{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "IbiYX3N_mx1-"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import LinearSVC  # Using LinearSVC instead of SVC for speed\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from joblib import Parallel, delayed\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the datasets\n",
        "train_df = pd.read_csv('/content/RevisedHomesiteTrain1.csv')\n",
        "test_df = pd.read_csv('/content/RevisedHomesiteTest1.csv')"
      ],
      "metadata": {
        "id": "jSNy7OYknFWv"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features and target\n",
        "X = train_df.drop(['QuoteConversion_Flag', 'QuoteNumber'], axis=1)\n",
        "y = train_df['QuoteConversion_Flag']\n",
        "test_ids = test_df['QuoteNumber']\n",
        "X_test = test_df.drop('QuoteNumber', axis=1)\n"
      ],
      "metadata": {
        "id": "oLNd2L4enM_i"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure column alignment\n",
        "common_columns = list(set(X.columns) & set(X_test.columns))\n",
        "X = X[common_columns]\n",
        "X_test = X_test[common_columns]\n",
        "\n",
        "print(f\"Number of features: {len(common_columns)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEPwBpbkn9Qo",
        "outputId": "597755a0-fc9b-4dd0-9e7b-93e198de47dd"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of features: 594\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data\n",
        "print(\"Splitting data...\")\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features\n",
        "print(\"Scaling features...\")\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
        "X_val_scaled = pd.DataFrame(scaler.transform(X_val), columns=X_val.columns)\n",
        "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zls7lG1WoCZU",
        "outputId": "cc518952-6503-46f0-a91f-09b0f299fa80"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Splitting data...\n",
            "Scaling features...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature selection with fewer features\n",
        "print(\"Performing feature selection...\")\n",
        "k = 100  # Reduced number of features\n",
        "selector = SelectKBest(f_classif, k=k)\n",
        "X_train_selected = selector.fit_transform(X_train_scaled, y_train)\n",
        "X_val_selected = selector.transform(X_val_scaled)\n",
        "X_test_selected = selector.transform(X_test_scaled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSaefiqOoGNl",
        "outputId": "c95d30fa-c00e-49bb-a64a-9da5740abfab"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing feature selection...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to DataFrame with selected feature names\n",
        "selected_features = X_train_scaled.columns[selector.get_support()].tolist()\n",
        "X_train_selected = pd.DataFrame(X_train_selected, columns=selected_features)\n",
        "X_val_selected = pd.DataFrame(X_val_selected, columns=selected_features)\n",
        "X_test_selected = pd.DataFrame(X_test_selected, columns=selected_features)\n",
        "\n"
      ],
      "metadata": {
        "id": "8-iPJ6_4oKnS"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize optimized base models\n",
        "base_models = {\n",
        "    'mlp': MLPClassifier(hidden_layer_sizes=(50,), max_iter=100, random_state=42),\n",
        "    'svm': LinearSVC(random_state=42),  # Faster than SVC\n",
        "    'dt': DecisionTreeClassifier(max_depth=5, random_state=42),\n",
        "    'rf': RandomForestClassifier(n_estimators=50, max_depth=5, n_jobs=-1, random_state=42),\n",
        "    'knn': KNeighborsClassifier(n_neighbors=5, n_jobs=-1)\n",
        "}"
      ],
      "metadata": {
        "id": "JHZUvpZPoPRb"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to train a single model\n",
        "def train_model(name, model, X_train, y_train, X_val):\n",
        "    model.fit(X_train, y_train)\n",
        "    if hasattr(model, 'predict_proba'):\n",
        "        pred_proba = model.predict_proba(X_val)[:, 1]\n",
        "    else:\n",
        "        # For LinearSVC, convert decision function to pseudo-probabilities\n",
        "        decision_values = model.decision_function(X_val)\n",
        "        pred_proba = 1 / (1 + np.exp(-decision_values))\n",
        "    return name, model, pred_proba\n"
      ],
      "metadata": {
        "id": "tH8eblgHoUfJ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to train models with multiple SMOTE ratios\n",
        "def train_with_multiple_smote_ratios(X_train, y_train, X_val, y_val, smote_ratios=[0.5, 0.75, 1.0]):\n",
        "    all_results = {}\n",
        "    best_score = 0\n",
        "    best_ratio = None\n",
        "    best_predictions = None\n",
        "    best_models = None\n",
        "\n",
        "    for ratio in smote_ratios:\n",
        "        print(f\"\\nTraining with SMOTE ratio: {ratio}\")\n",
        "        smote = SMOTE(sampling_strategy=ratio, random_state=42, n_jobs=-1)\n",
        "        X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "        # Train models in parallel\n",
        "        results = Parallel(n_jobs=-1)(\n",
        "            delayed(train_model)(name, model, X_train_resampled, y_train_resampled, X_val)\n",
        "            for name, model in base_models.items()\n",
        "        )\n",
        "\n",
        "        predictions = {}\n",
        "        trained_models = {}\n",
        "        ratio_scores = []\n",
        "\n",
        "        for name, model, pred_proba in results:\n",
        "            predictions[name] = pred_proba\n",
        "            trained_models[name] = model\n",
        "            score = roc_auc_score(y_val, pred_proba)\n",
        "            ratio_scores.append(score)\n",
        "            print(f\"{name} ROC AUC: {score:.4f}\")\n",
        "            # Store results for this ratio\n",
        "        all_results[ratio] = {\n",
        "            'predictions': predictions,\n",
        "            'models': trained_models,\n",
        "            'scores': ratio_scores,\n",
        "            'mean_score': np.mean(ratio_scores)\n",
        "        }\n",
        "\n",
        "        # Update best results if current ratio performs better\n",
        "        if all_results[ratio]['mean_score'] > best_score:\n",
        "            best_score = all_results[ratio]['mean_score']\n",
        "            best_ratio = ratio\n",
        "            best_predictions = predictions\n",
        "            best_models = trained_models\n",
        "\n",
        "    print(f\"\\nResults for all SMOTE ratios:\")\n",
        "    for ratio in smote_ratios:\n",
        "        print(f\"SMOTE ratio {ratio}: Mean ROC AUC = {all_results[ratio]['mean_score']:.4f}\")\n",
        "\n",
        "    print(f\"\\nBest SMOTE ratio: {best_ratio} (Mean ROC AUC: {best_score:.4f})\")\n",
        "\n",
        "    return best_predictions, best_models, all_results, best_ratio"
      ],
      "metadata": {
        "id": "yZKcAM7noWBz"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train models with different SMOTE ratios\n",
        "print(\"Training models with different SMOTE ratios...\")\n",
        "smote_ratios = [0.5, 0.75, 1.0]\n",
        "predictions, trained_models, all_smote_results, best_ratio = train_with_multiple_smote_ratios(\n",
        "    X_train_selected, y_train,\n",
        "    X_val_selected, y_val,\n",
        "    smote_ratios\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1d3oran7byd",
        "outputId": "a41cb6cc-ac42-42d7-bab2-20db9d06f53e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training models with different SMOTE ratios...\n",
            "\n",
            "Training with SMOTE ratio: 0.5\n",
            "mlp ROC AUC: 0.9383\n",
            "svm ROC AUC: 0.9354\n",
            "dt ROC AUC: 0.9111\n",
            "rf ROC AUC: 0.9013\n",
            "knn ROC AUC: 0.8845\n",
            "\n",
            "Training with SMOTE ratio: 0.75\n",
            "mlp ROC AUC: 0.9354\n",
            "svm ROC AUC: 0.9355\n",
            "dt ROC AUC: 0.9108\n",
            "rf ROC AUC: 0.9035\n",
            "knn ROC AUC: 0.8802\n",
            "\n",
            "Training with SMOTE ratio: 1.0\n",
            "mlp ROC AUC: 0.9345\n",
            "svm ROC AUC: 0.9355\n",
            "dt ROC AUC: 0.9097\n",
            "rf ROC AUC: 0.9012\n",
            "knn ROC AUC: 0.8784\n",
            "\n",
            "Results for all SMOTE ratios:\n",
            "SMOTE ratio 0.5: Mean ROC AUC = 0.9141\n",
            "SMOTE ratio 0.75: Mean ROC AUC = 0.9131\n",
            "SMOTE ratio 1.0: Mean ROC AUC = 0.9119\n",
            "\n",
            "Best SMOTE ratio: 0.5 (Mean ROC AUC: 0.9141)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create meta-features using predictions from best models\n",
        "meta_features = np.column_stack([predictions[name] for name in base_models.keys()])\n",
        "\n",
        "# Simple hyperparameter optimization using a smaller set of parameters\n",
        "print(\"\\nPerforming simplified hyperparameter optimization...\")\n",
        "\n",
        "# List of configurations to try\n",
        "configs = [\n",
        "    {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'},\n",
        "    {'C': 1.0, 'penalty': 'l2', 'solver': 'liblinear'},\n",
        "    {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
        "]\n",
        "\n",
        "# Try each configuration and keep track of the best one\n",
        "best_score = 0\n",
        "best_model = None\n",
        "best_params = None\n",
        "\n",
        "for params in configs:\n",
        "    print(f\"Trying parameters: {params}\")\n",
        "    meta_model = LogisticRegression(**params, max_iter=200)\n",
        "    meta_model.fit(meta_features, y_val)\n",
        "    score = meta_model.score(meta_features, y_val)\n",
        "\n",
        "    if score > best_score:\n",
        "        best_score = score\n",
        "        best_model = meta_model\n",
        "        best_params = params\n",
        "\n",
        "print(\"\\nBest meta-model parameters:\", best_params)\n",
        "print(\"Best meta-model score:\", best_score)\n",
        "\n",
        "# Generate test predictions using best models\n",
        "print(\"\\nGenerating final predictions...\")\n",
        "meta_features_test = np.zeros((X_test_selected.shape[0], len(base_models)))\n",
        "\n",
        "# Use trained_models from the previous step instead of accessing smote_results\n",
        "for i, (name, model) in enumerate(trained_models.items()):\n",
        "    # Check if model has predict_proba method\n",
        "    if hasattr(model, 'predict_proba'):\n",
        "        meta_features_test[:, i] = model.predict_proba(X_test_selected)[:, 1]\n",
        "    else:\n",
        "        # For models like LinearSVC, use decision_function and convert to pseudo-probabilities\n",
        "        decision_values = model.decision_function(X_test_selected)\n",
        "        # Convert to probabilities using sigmoid function\n",
        "        meta_features_test[:, i] = 1 / (1 + np.exp(-decision_values))\n",
        "\n",
        "# Final predictions using best meta-model\n",
        "final_predictions = best_model.predict_proba(meta_features_test)[:, 1]\n",
        "\n",
        "# Create submission file\n",
        "submission = pd.DataFrame({\n",
        "    'QuoteNumber': test_ids,\n",
        "    'QuoteConversion_Flag': final_predictions\n",
        "})\n",
        "submission.to_csv('stacked_submission.csv', index=False)\n",
        "\n",
        "# Create final performance summary\n",
        "final_performance = pd.DataFrame({\n",
        "    'Model': list(base_models.keys()) + ['Stacked Model'],\n",
        "    'ROC AUC Score': [roc_auc_score(y_val, predictions[name]) for name in base_models.keys()] +\n",
        "                    [best_score],\n",
        "    'SMOTE Ratio': [best_ratio] * (len(base_models) + 1)\n",
        "})\n",
        "\n",
        "# Save final performance summary\n",
        "final_performance.to_excel('final_model_performance.xlsx', index=False)\n",
        "\n",
        "print(\"\\nFinal Performance Summary:\")\n",
        "print(final_performance)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ba25VUCc8-zb",
        "outputId": "9e7cedb1-a62d-4ffb-b779-524220bbeb7d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Performing simplified hyperparameter optimization...\n",
            "Trying parameters: {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "Trying parameters: {'C': 1.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "Trying parameters: {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "\n",
            "Best meta-model parameters: {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Best meta-model score: 0.9143846153846154\n",
            "\n",
            "Generating final predictions...\n",
            "\n",
            "Final Performance Summary:\n",
            "           Model  ROC AUC Score  SMOTE Ratio\n",
            "0            mlp       0.938334          0.5\n",
            "1            svm       0.935449          0.5\n",
            "2             dt       0.911051          0.5\n",
            "3             rf       0.901272          0.5\n",
            "4            knn       0.884477          0.5\n",
            "5  Stacked Model       0.914385          0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate test predictions\n",
        "print(\"Generating test predictions...\")\n",
        "meta_features_test = np.zeros((X_test_selected.shape[0], len(base_models)))\n",
        "for i, (name, model) in enumerate(trained_models.items()):\n",
        "    if hasattr(model, 'predict_proba'):\n",
        "        meta_features_test[:, i] = model.predict_proba(X_test_selected)[:, 1]\n",
        "    else:\n",
        "        decision_values = model.decision_function(X_test_selected)\n",
        "        meta_features_test[:, i] = 1 / (1 + np.exp(-decision_values))\n",
        "\n",
        "# Make final predictions\n",
        "final_predictions = meta_model.predict_proba(meta_features_test)[:, 1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1oxqhM1o7x3",
        "outputId": "66698ffd-cd72-467c-fa9a-c472a981ac6e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating test predictions...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create submission file\n",
        "print(\"Creating submission file...\")\n",
        "submission = pd.DataFrame({\n",
        "    'QuoteNumber': test_ids,\n",
        "    'QuoteConversion_Flag': final_predictions\n",
        "})\n",
        "submission.to_csv('stacked_submission.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8Gdlcluo_sd",
        "outputId": "68cde15d-eeb4-4cf3-9c9c-61f013baf8a8"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating submission file...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create performance summary\n",
        "print(\"Creating performance summary...\")\n",
        "performance_summary = pd.DataFrame({\n",
        "    'Model': list(base_models.keys()) + ['Stacked Model'],\n",
        "    'ROC AUC Score': [roc_auc_score(y_val, predictions[name]) for name in base_models.keys()] +\n",
        "                    [roc_auc_score(y_val, meta_model.predict_proba(meta_features)[:, 1])],\n",
        "    'SMOTE Strategy': [0.75] * (len(base_models) + 1)\n",
        "})\n",
        "\n",
        "# Save performance summary\n",
        "performance_summary.to_excel('model_performance.xlsx', index=False)\n",
        "\n",
        "print(\"\\nPerformance Summary:\")\n",
        "print(performance_summary)\n",
        "\n",
        "print(\"\\nProcess completed successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cr4B59iNpDBi",
        "outputId": "969e4cc7-923a-4e62-f4b2-11ea568be2cd"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating performance summary...\n",
            "\n",
            "Performance Summary:\n",
            "           Model  ROC AUC Score  SMOTE Strategy\n",
            "0            mlp       0.938334            0.75\n",
            "1            svm       0.935449            0.75\n",
            "2             dt       0.911051            0.75\n",
            "3             rf       0.901272            0.75\n",
            "4            knn       0.884477            0.75\n",
            "5  Stacked Model       0.947056            0.75\n",
            "\n",
            "Process completed successfully!\n"
          ]
        }
      ]
    }
  ]
}